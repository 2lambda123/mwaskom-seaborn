{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      ".. _linear_quantitative::\n",
      "\n",
      ".. currentmodule:: seaborn"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Linear models with quantitative data"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Linear models are very common in statistical analysis. They are used to understand how linear combinations of *predictor* (or *independent*) variables relate to a *response* (or *dependent*) variable. Seaborn has several functions for exploratory visualizations that correspond with linear regression. This page will focus on the functions that can be used when the main predictor variable (or variables) are quantitative. They differ from functions focused on :ref:`categorical variables <linear_categorical>` in that they fit and plot a representation of the model itself in the form of a regression line."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(sum(map(ord, \"linear_quantitative\")))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      ".. _lmplot:\n",
      "\n",
      "Visualizing multiple regression with :func:`lmplot`\n",
      "---------------------------------------------------\n",
      "\n",
      "The :func:`lmplot` function is intended for exploring linear relationships of different forms in multidimensional datesets. Input data must be in a Pandas ``DataFrame`. To plot, provide the predictor and response variable names along with the dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tips = pd.read_csv(\"https://raw2.github.com/mwaskom/seaborn-data/master/tips.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"tip\", tips);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "This plot has two main components. The first is a scatterplot, showing the observed datapoints. The second is a regression line, showing the estimated linear model relating the two variables. Because the regression line is only an *estimate*, it is plotted with a 95% confidence band to give an impression of the certainty in the model. You can plot different levels of certainty. For instance, it is common to plot the *standard error* of an estimate, which corresponds to the 68% confidence interval."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"tip\", tips, ci=68);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Hopefully, the default aesthetics are suitable for exploratory graphics. However, you  can also control the aesthetics of the underlying plots separately through dictionaries of keyword arguments for the matplotlib ``scatter`` and ``plot`` functions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"tip\", tips,\n",
      "           scatter_kws={\"marker\": \".\", \"color\": \"slategray\"},\n",
      "           line_kws={\"linewidth\": 1, \"color\": \"seagreen\"});"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Plotting with discrete predictor variables\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "Sometimes you will want to plot data where the independent variable is quantitative, but discrete. Although this works fine out of the box:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"size\", \"tip\", tips);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "And can be improved with a bit of jitter:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"size\", \"tip\", tips, x_jitter=.15);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "It might be more informative to estimate the central tendency of each bin. This is easy to do with the x_estimator argument. Just pass any function that aggregates a vector of data into one estimate. The estimator will be bootstrapped and a confidence interval will be plotted -- 95% by default, as in other cases within these functions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"size\", \"tip\", tips, x_estimator=np.mean);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "It can also be useful to bin continuous predictor variable into discrete values and plot an estimated central tendency and confidence interval. This can be helpful when you have many datapoints and a reliable, but weak, effect. Note that the regression estimate will still fit to the original data; the binning only applies to the visual representation of the observations.\n",
      "\n",
      "With :func:`lmplot`, you can provide specific centroid values for the bins:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bins = [10, 20, 30, 40]\n",
      "sns.lmplot(\"total_bill\", \"tip\", tips, x_bins=bins);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Or, you can give a number of bins and it will find centroids so that they have equal numbers of datapoints in them:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"tip\", tips, x_bins=8);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Faceted linear model plots\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "The :func:`lmplot` function is built on top of a :class:`FacetGrid`. That means it's easy to visualize how this relationship changes in different subsets of your dataset. You can read the extended :ref:`documentation <facet_grid>` for more details on how the :class:`FacetGrid` class works. The important thing is that you can supply the names of categorical variables that define subsets of the data to plot in different hues or along the row and columns of a grid of axes.\n",
      "\n",
      "Using a `hue` facet makes it easiest to directly compare the two subsets:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"tip\", tips, hue=\"smoker\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Plotting in different columns of a grid also makes a plot that's easy to understand, although direct comparisons between the subsets are more difficult as the data are separated in space. This might be better when you want the viewer to focus on the relationship within each subset independently."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"tip\", tips, col=\"smoker\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "You can also assign the same variable to multiple roles. This lets you plot the data separately and use color to semantically tag differnt subsets of the data. Using color in this way can be helpful when you are making multiple different kind of plots, and you want to help connect them visually."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"tip\", tips, col=\"smoker\", hue=\"smoker\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      ":func:`lmplot` accepts all arguments that you would use to initialize a :class:`FacetGrid`, and it returns the grid object after plotting for further tweaking:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = sns.lmplot(\"total_bill\", \"tip\", tips, hue=\"day\", palette=\"Set2\",\n",
      "               hue_order=[\"Thur\", \"Fri\", \"Sat\", \"Sun\"])\n",
      "g.set_axis_labels(\"Total bill (US Dollars)\", \"Tip\");\n",
      "g.set(xticks=[10, 30, 50], ylim=(0, 10), yticks=[0, 2.5, 5, 7.5, 10]);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Plotting different linear relationships\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "By default, :func:`lmplot` shows the ordinary least squares fit to the data. However, you don't actually need to fit a regression at all:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"tip\", tips, hue=\"time\", palette=\"Set1\", fit_reg=False);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "There are several other choices for how to fit the regression. These options are mutally exclusive. \n",
      "\n",
      "Plotting nonlinear trends\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "You might, for example, wonder if the relationship follows a higher-order trend:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"size\", \"total_bill\", tips, order=2);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "For an even more flexible fit, you can plot the *lowess* line, which is a nonparametric approach to regression. Note that, currently, lowess plots don't plot a confidence interval around the line."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"tip\", tips, lowess=True, line_kws={\"color\": \".2\"});"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Plotting logistic regression\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Let's define a dependent measure that takes the values ``True`` and ``False``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tips[\"big_tip\"] = (tips[\"tip\"] / tips[\"total_bill\"]) > .15"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "It's possible to plot (and fit) these data as normal:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"big_tip\", tips);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "This plot suggests that diners with a larger total bill are less likely to leave a big tip, but it has a few issues. The first is that the individual observations are all plotted on top of each other, so their distribution is obscured. We can address this issue by adding a bit of jitter to the scatter plot."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"big_tip\", tips, y_jitter=.05);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "A more fundamental problem follows from using basic linear regression with a binary response variable. You might want to read the y axis as the *probability* of a big tip, but this regression line implies a negative probability when the bill is greater than $50. Because that doesn't make sense, :func:`lmplot` can fit a *logistic regression* and plot the resulting curve over the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"big_tip\", tips, y_jitter=.05, logistic=True);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Plotting data with outliers\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Sometimes, data will have outliers. Because linear regression is based on the mean, it can be overly influenced by outliers, especially in cases with relatively few datapoints. :func:`lmplot` can also plot the regression model using robust estimation, which reduces the influence of outlying points.\n",
      "\n",
      "Robust estimation is computationally intensive, so you may want to reduce the number of bootstrap iterations when using it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"total_bill\", \"tip\", tips, robust=True, n_boot=500);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Controlling for confounding variables\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "A major feature of multiple regression is the ability to \"control for\" confounding variables. Seaborn brings this ability into the visualiation realm, allowing you to regress variables out of the predictor and/or response variables before plotting. Let's make a simple three-variable dataset where variables A and B appear related, but are actually independent once you account for variable C."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = np.random.randn(50)\n",
      "a = 2 + c + np.random.randn(50)\n",
      "b = 3 + c + np.random.randn(50)\n",
      "df = pd.DataFrame(dict(A=a, B=b, C=c), columns=list(\"ABC\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "If you plot the relationship between A and B, they will look related:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"A\", \"B\", df);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "However, if you remove (or \"partial out\") variable C from variable A before plotting, you can see that they are in fact independent."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.lmplot(\"A\", \"B\", df, x_partial=\"C\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      ".. _regplot:\n",
      "\n",
      "Plotting simple regression with :func:`regplot`\n",
      "-----------------------------------------------\n",
      "\n",
      "For most exploratory uses, :func:`lmplot` should easily produce an informative graphic. In some cases, though, you may want to draw a scatterplot and regression model in the context of a figure with different subplots. Becuase the :class:`FacetGrid` initializes its own figure and controls the whole subplot grid, it can't be used here.\n",
      "\n",
      "In fact, :func:`lmplot` is just using a lower-level function, :func:`regplot`, to draw the data and the regression line. :func:`regplot` is lower-level in the sense that it can plot onto an existing Axes and doesn't modify anything about the figure it will be drawn onto. In situations where you want more control, it might be advantageous to use :func:`regplot` directly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
      "sns.regplot(\"total_bill\", \"tip\", tips, ax=ax1)\n",
      "sns.boxplot(tips[\"tip\"], tips[\"size\"], color=\"Blues_r\", ax=ax2).set_ylabel(\"\")\n",
      "f.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Because :func:`lmplot` is using :func:`regplot` behind the scenes, all of the options for binning the datapoints, fitting the regression, and modifying the aesthetics are shared. What's missing from :func:`regplot` is the faceting options, so each call can only draw a single scatterplot and regression line.\n",
      "\n",
      "The other difference is that :func:`regplot` also accepts data passed directly as numpy arrays or pandas series objects, if you don't have your data organized into a dataframe. You can also directly control the color of the plot:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x, y = np.random.multivariate_normal([1, 5], [(2, -.8), (-.8, 2)], 80).T\n",
      "ax = sns.regplot(x, y, color=\"seagreen\")\n",
      "ax.set(xlabel=\"x variable\", ylabel=\"y variable\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      ".. _interactplot:\n",
      "\n",
      "Describing continuous interactions with :func:`interactplot`\n",
      "------------------------------------------------------------\n",
      "\n",
      "Hopefully, :func:`lmplot` is useful for a variety of visualization problems. However, one limitation is that it can plot, at most, a single continuous predictor variable. Although two-way interactions between continuous variables are often interesting, they can be difficult to visualize and understand.\n",
      "\n",
      "Let's make some fake data with a two-way interaction to show how you might approach this problem."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rs = np.random.RandomState(1)\n",
      "x1, x2 = rs.normal(size=(2, 100))\n",
      "y1 = .5 * x1 + 2 * x2 + 2 * x1 * x2 + rs.normal(size=100)\n",
      "y2 = x1 + x2 + rs.normal(size=100)\n",
      "p = 1 / (1 + np.exp(-y1))\n",
      "y_flip = [rs.binomial(1, p_i) for p_i in p]\n",
      "df = pd.DataFrame(dict(x1=x1, x2=x2, y1=y1, y2=y2, y_flip=y_flip))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "One approach is to bin one of the predictors and then plot the data as before, treating the predictor as categorical."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bins = np.array([-1, 0, 1])\n",
      "binned = np.digitize(x2, bins)\n",
      "df[\"x2_bin\"] = binned\n",
      "sns.lmplot(\"x1\", \"y1\", df, col=\"x2_bin\", hue=\"x2_bin\", palette=\"PuBuGn_d\", size=3);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "This is servicable, but lacking in several ways. It requires several cumbersome steps, the choice of the bin size is arbitrary, and collapsing the continuous data into categories loses information.\n",
      "\n",
      "An alternative approach plots the two independent variables on the x and y axes of a plot and color-encodes the model predictions with a contour plot. This maintains the continuous nature of the data. The seaborn function :func:`interactplot` draws such a plot using an interface similar to :func:`regplot`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.interactplot(x1, x2, y1);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Naturally, you can directly pass a dataframe and adjust the aesthetics of the plot:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.interactplot(\"x1\", \"x2\", \"y1\", df, cmap=\"coolwarm\", filled=True, levels=25);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "The two underlying plot functions are ``contourf()`` and ``plot()``, both of which can be tweaked with a keyword argument dictionary.\n",
      "\n",
      "Note the appearance when we plot data that was not simulated with an interaction:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.interactplot(\"x1\", \"x2\", \"y2\", df, filled=True,\n",
      "                 scatter_kws={\"color\": \"dimgray\"},\n",
      "                 contour_kws={\"alpha\": .5});"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "This works for logistic regression too:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pal = sns.blend_palette([\"#4169E1\", \"#DFAAEF\", \"#E16941\"], as_cmap=True)\n",
      "levels = np.linspace(0, 1, 11)\n",
      "sns.interactplot(\"x1\", \"x2\", \"y_flip\", df, levels=levels, cmap=pal, logistic=True);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "We hope that this collection of features will help you understand the relationships in your datasets. Please get in touch if you have a visualization problem in this domain that these tools don't seem suited for."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}